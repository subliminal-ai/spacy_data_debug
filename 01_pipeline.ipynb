{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline\n",
    "\n",
    "> A `Pipeline` keeps track of your train/dev/test split and provides the same debug functionality for each dataset and for all data combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from typing import List, Dict\n",
    "from spacy_data_debug.core import *\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self, train: List[Dict[str, object]], dev: List[Dict[str, object]], test: List[Dict[str, object]] = None):\n",
    "        self.datasets = {\n",
    "            'train': train,\n",
    "            'dev': dev,\n",
    "            'all': train + dev\n",
    "        }\n",
    "        if test:\n",
    "            self.datasets.update({\n",
    "                'test': test,\n",
    "                'all': train + dev + test\n",
    "            })\n",
    "    \n",
    "    def apply(self, func, *args, **kwargs):\n",
    "        \"\"\"Apply an existing function to all datasets\"\"\"\n",
    "        res = {}\n",
    "        for k, dataset in self.datasets.items():\n",
    "            res[k] = func(dataset, *args, **kwargs)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "train = list(srsly.read_jsonl(\"../CognitiveServices/API-TextAnalytics-NER.CloudServices/data/2020-01-23/cs_train.jsonl\"))\n",
    "dev = list(srsly.read_jsonl(\"../CognitiveServices/API-TextAnalytics-NER.CloudServices/data/2020-01-23/cs_dev.jsonl\"))\n",
    "test = list(srsly.read_jsonl(\"../CognitiveServices/API-TextAnalytics-NER.CloudServices/data/2020-01-23/cs_test.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"n_examples\":130000,\n",
      "    \"n_examples_no_entities\":7,\n",
      "    \"ents_per_type\":{\n",
      "        \"AGE\":2999,\n",
      "        \"LOCATION\":52346,\n",
      "        \"PERSONTYPE\":69290,\n",
      "        \"SET\":1505,\n",
      "        \"GPE\":89942,\n",
      "        \"DATERANGE\":42247,\n",
      "        \"EVENT\":20088,\n",
      "        \"NUMBER\":18604,\n",
      "        \"ORGANIZATION\":56557,\n",
      "        \"PERSON\":92811,\n",
      "        \"PRODUCT\":18102,\n",
      "        \"DATE\":13304,\n",
      "        \"PERCENTAGE\":3698,\n",
      "        \"DURATION\":8584,\n",
      "        \"ADDRESS\":2938,\n",
      "        \"CURRENCY\":4355,\n",
      "        \"TIME\":746,\n",
      "        \"TIMERANGE\":654,\n",
      "        \"DATETIMERANGE\":647,\n",
      "        \"NUM_RANGE\":340\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"n_examples\":150000,\n",
      "    \"n_examples_no_entities\":2090,\n",
      "    \"ents_per_type\":{\n",
      "        \"AGE\":3314,\n",
      "        \"LOCATION\":58316,\n",
      "        \"PERSONTYPE\":79047,\n",
      "        \"SET\":1776,\n",
      "        \"GPE\":99444,\n",
      "        \"DATERANGE\":46663,\n",
      "        \"EVENT\":23146,\n",
      "        \"NUMBER\":21522,\n",
      "        \"ORGANIZATION\":64229,\n",
      "        \"PERSON\":102088,\n",
      "        \"PRODUCT\":22885,\n",
      "        \"DATE\":14653,\n",
      "        \"PERCENTAGE\":4347,\n",
      "        \"DURATION\":9788,\n",
      "        \"ADDRESS\":3170,\n",
      "        \"CURRENCY\":5039,\n",
      "        \"TIME\":818,\n",
      "        \"TIMERANGE\":773,\n",
      "        \"DATETIMERANGE\":703,\n",
      "        \"NUM_RANGE\":405,\n",
      "        \"Time\":1\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(train, dev, test)\n",
    "res = pipeline.apply(dataset_stats, serialize=True)\n",
    "print(res['train'])\n",
    "print(res['all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_pipeline.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
